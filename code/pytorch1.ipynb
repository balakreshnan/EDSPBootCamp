{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a22c772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f2b2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.ext.blackbox import TabularExplainer\n",
    "from raiwidgets import ExplanationDashboard\n",
    "from raiwidgets import FairnessDashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfceb044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3680c0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0172ed61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1433bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ef7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3bd279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62aba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a649a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Sample_IssueDataset.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2061d328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaafc1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45958a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b35b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b903effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df1.iloc[:,1]\n",
    "X = df1.iloc[:,:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['EmployeeLeft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde26c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e80c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7a99c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c431c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e121669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_torch = torch.tensor(X_train.values)\n",
    "X_test_torch = torch.tensor(X_test.values)\n",
    "y_train_torch = torch.tensor(y_train.values)\n",
    "y_test_torch = torch.tensor(y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98c3932",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e7bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(9380*17, 10),\n",
    "            nn.ReLU(),\n",
    "            #nn.Linear(9380*17, 10),\n",
    "            #nn.ReLU(),\n",
    "            nn.Linear(9380*17, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5873b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten = nn.Flatten()\n",
    "#flat_image = flatten(X_train_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3457e745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#logits = model(X_train_torch)\n",
    "#pred_probab = nn.Softmax(dim=1)(logits)\n",
    "#y_pred = pred_probab.argmax(1)\n",
    "#print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bb3b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df40dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    " \n",
    "train_features = torch.tensor(X_train.to_numpy())\n",
    "train_labels = torch.tensor(y_train.to_numpy())\n",
    " \n",
    "validation_features = torch.tensor(X_test.to_numpy())\n",
    "validation_labels = torch.tensor(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e557e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = X_train.shape[1]\n",
    "# 31\n",
    "model = torch.nn.Sequential(torch.nn.Linear(n_features, 18),\n",
    "                            torch.nn.ReLU(),\n",
    "                            torch.nn.Linear(18, 1),\n",
    "                            torch.nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b752e7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c662d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_torch.shape\n",
    "y_train_torch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe2d624",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batches = 2\n",
    "train_features_batched = train_features.reshape(n_batches,\n",
    "                                               int(train_features.shape[0]/n_batches),\n",
    "                                               train_features.shape[1])\n",
    "train_labels_batched = train_labels.reshape(n_batches,\n",
    "                                            int(train_labels.shape[0]/n_batches))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c623d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "loss_list = []\n",
    "validate_loss_list = []\n",
    " \n",
    "for epoch in range(n_epochs):\n",
    "    for batch_idx in range(n_batches):\n",
    "        optimizer.zero_grad()\n",
    "         \n",
    "        outputs = model(train_features_batched[batch_idx].float())\n",
    "         \n",
    "     \n",
    "        loss = criterion(outputs.flatten().float(),\n",
    "                         train_labels_batched[batch_idx].float())\n",
    "     \n",
    "         \n",
    "        loss.backward()\n",
    "         \n",
    "        optimizer.step()\n",
    "         \n",
    "    outputs = model(train_features.float())\n",
    "     \n",
    "    validation_outputs = model(validation_features.float())\n",
    "     \n",
    "         \n",
    "    loss = criterion(outputs.flatten().float(),\n",
    "                     train_labels.float())\n",
    "     \n",
    "    validate_loss = criterion(validation_outputs.flatten().float(),\n",
    "                              validation_labels.float())\n",
    "     \n",
    "    loss_list.append(loss.item())\n",
    "     \n",
    "    validate_loss_list.append(validate_loss)\n",
    " \n",
    "print('Finished Training')\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_list, linewidth=3)\n",
    "plt.plot(validate_loss_list, linewidth=3)\n",
    "plt.legend((\"Training Loss\", \"Validation Loss\"))\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"BCE Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ff108",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://danielmuellerkomorowska.com/2021/02/03/a-deep-feedforward-network-in-pytorch-for-the-titanic-challenge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e036bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(validation_features[1].flatten().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3fb235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd06e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e184d8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(validation_features.flatten().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b953a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34db06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(validation_features[0].flatten().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00331856",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9c64c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(validation_features[0].flatten().float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9e83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before_train = criterion(y_pred.squeeze(), validation_features[0].flatten().float())\n",
    "#print('Test loss before training' , before_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff8976",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "epochs = 5\n",
    "errors = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model(train_features.float())\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred.squeeze(), train_labels.float())\n",
    "    errors.append(loss.item())\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518be76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "epochs = 500\n",
    "errors = []\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    y_pred = model(validation_features.float())\n",
    "    # Compute Loss\n",
    "    loss = criterion(y_pred.squeeze(), validation_labels.float())\n",
    "    errors.append(loss.item())\n",
    "    print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5043c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plotcharts(errors):\n",
    "    errors = np.array(errors)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index\n",
    "    graf02.set_title('Errors')\n",
    "    plt.plot(errors, '-')\n",
    "    plt.xlabel('Epochs')\n",
    "    graf03 = plt.subplot(1, 2, 2)\n",
    "    graf03.set_title('Tests')\n",
    "    a = plt.plot(train_labels.numpy(), 'yo', label='Real')\n",
    "    plt.setp(a, markersize=10)\n",
    "    a = plt.plot(y_pred.detach().numpy(), 'b+', label='Predicted')\n",
    "    plt.setp(a, markersize=10)\n",
    "    plt.legend(loc=7)\n",
    "    plt.show()\n",
    "plotcharts(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0940e732",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "y_pred = model(validation_features.float())\n",
    "after_train = criterion(y_pred.squeeze(), validation_labels.float())\n",
    "print('Test loss after Training' , after_train.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def plotcharts(errors):\n",
    "    errors = np.array(errors)\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    graf02 = plt.subplot(1, 2, 1) # nrows, ncols, index\n",
    "    graf02.set_title('Errors')\n",
    "    plt.plot(errors, '-')\n",
    "    plt.xlabel('Epochs')\n",
    "    graf03 = plt.subplot(1, 2, 2)\n",
    "    graf03.set_title('Tests')\n",
    "    a = plt.plot(train_labels.numpy(), 'yo', label='Real')\n",
    "    plt.setp(a, markersize=10)\n",
    "    a = plt.plot(y_pred.detach().numpy(), 'b+', label='Predicted')\n",
    "    plt.setp(a, markersize=10)\n",
    "    plt.legend(loc=7)\n",
    "    plt.show()\n",
    "plotcharts(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afc7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.sigmoid(y_pred)\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb060c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1030ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedPytorchModel(object):\n",
    "    \"\"\"A class for wrapping a PyTorch model in the scikit-learn specification.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        \"\"\"Initialize the PytorchModelWrapper with the model and evaluation function.\"\"\"\n",
    "        self._model = model\n",
    "        # Set eval automatically for user for batchnorm and dropout layers\n",
    "        self._model.eval()\n",
    "\n",
    "    def predict(self, dataset):\n",
    "        \"\"\"Predict the output using the wrapped PyTorch model.\n",
    "        :param dataset: The dataset to predict on.\n",
    "        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper\n",
    "        \"\"\"\n",
    "        # Convert the data to pytorch Variable\n",
    "        if isinstance(dataset, pd.DataFrame):\n",
    "            dataset = dataset.values\n",
    "        wrapped_dataset = torch.Tensor(dataset)\n",
    "        with torch.no_grad():\n",
    "            result = self._model(wrapped_dataset).numpy()\n",
    "        # Reshape to 2D if output is 1D and input has one row\n",
    "        if len(dataset.shape) == 1:\n",
    "            result = result.reshape(1, -1)\n",
    "        return result\n",
    "\n",
    "    def predict_classes(self, dataset):\n",
    "        \"\"\"Predict the class using the wrapped PyTorch model.\n",
    "        :param dataset: The dataset to predict on.\n",
    "        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper\n",
    "        \"\"\"\n",
    "        # Convert the data to pytorch Variable\n",
    "        if isinstance(dataset, pd.DataFrame):\n",
    "            dataset = dataset.values\n",
    "        wrapped_dataset = torch.Tensor(dataset)\n",
    "        with torch.no_grad():\n",
    "            result = torch.max(self._model(wrapped_dataset), 1)[0].numpy()\n",
    "        # Reshape to 2D if output is 1D and input has one row\n",
    "        if len(dataset.shape) == 1:\n",
    "            result = result.reshape(1, -1)\n",
    "        return result\n",
    "\n",
    "    def predict_proba(self, dataset):\n",
    "        \"\"\"Predict the output probability using the wrapped PyTorch model.\n",
    "        :param dataset: The dataset to predict_proba on.\n",
    "        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper\n",
    "        \"\"\"\n",
    "        return self.predict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e605bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedClassificationMode(object):\n",
    "        def predict(self, dataset):\n",
    "            \"\"\"Predict the output using the wrapped classification model.\n",
    "            :param dataset: The dataset to predict on.\n",
    "            :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper\n",
    "            \"\"\"\n",
    "            is_sequential = str(type(self._model)).endswith(\"tensorflow.python.keras.engine.sequential.Sequential'>\")\n",
    "            #print('before')\n",
    "            if is_sequential or isinstance(self._model, WrappedPytorchModel):\n",
    "                return self._model.predict_classes(dataset).flatten()\n",
    "            #print('after')\n",
    "            preds = self._model.predict(dataset)\n",
    "            if isinstance(preds, pd.DataFrame):\n",
    "                preds = preds.values.ravel()\n",
    "            # Handle possible case where the model has only a predict function and it outputs probabilities\n",
    "            # Note this is different from WrappedClassificationWithoutProbaModel where there is no predict_proba\n",
    "            # method but the predict method outputs classes\n",
    "            has_predict_proba = hasattr(self._model, SKLearn.PREDICT_PROBA)\n",
    "            if not has_predict_proba:\n",
    "                if len(preds.shape) == 1:\n",
    "                    return np.argmax(preds)\n",
    "                else:\n",
    "                    return np.argmax(preds, axis=1)\n",
    "            return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dbed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedClassificationModel(object):\n",
    "    \"\"\"A class for wrapping a classification model.\"\"\"\n",
    "\n",
    "    def __init__(self, model, eval_function):\n",
    "        \"\"\"Initialize the WrappedClassificationModel with the model and evaluation function.\"\"\"\n",
    "        self._eval_function = eval_function\n",
    "        self._model = model\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, dataset):\n",
    "        probabilities = self._model.predict_classes(dataset).flatten()\n",
    "        return [1 if proba > 0.5 else 0 for proba in probabilities]\n",
    "#        return self._model.predict_classes(dataset).flatten()\n",
    "\n",
    "    def predict_proba(self, dataset):\n",
    "        \"\"\"Predict the output probability using the wrapped model.\n",
    "        :param dataset: The dataset to predict_proba on.\n",
    "        :type dataset: interpret_community.dataset.dataset_wrapper.DatasetWrapper\n",
    "        \"\"\"\n",
    "        proba_preds = self._eval_function(dataset)\n",
    "        if isinstance(proba_preds, pd.DataFrame):\n",
    "            proba_preds = proba_preds.values\n",
    "\n",
    "        return proba_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbeaa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from interpret_community.common.model_wrapper import WrappedClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5857bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret_community.common.model_wrapper import _eval_model\n",
    "from interpret_community.common.model_wrapper import wrap_model\n",
    "from interpret_community.dataset.dataset_wrapper import DatasetWrapper\n",
    "eval_function, eval_ml_domain = _eval_model(WrappedPytorchModel(model), DatasetWrapper(validation_features.float()), \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90038b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = WrappedClassificationModel(WrappedPytorchModel(model), eval_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937e9e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f681378",
   "metadata": {},
   "outputs": [],
   "source": [
    "#newmodel.predict_classes(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6befeb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel.predict(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = newmodel.predict(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefbb693",
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel.predict_proba(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ec4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "WrappedPytorchModel(model).predict_classes(validation_features.float()).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efe6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    result = torch.max(model(validation_features.float()), 1)[1].numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315f6c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#    result = model(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b76c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.max(model(validation_features.float()),1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc7475",
   "metadata": {},
   "outputs": [],
   "source": [
    "3result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ca3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from interpret_community.common.model_wrapper import wrap_model\n",
    "#from interpret_community.dataset.dataset_wrapper import DatasetWrapper\n",
    "#wrapped_model, ml_domain = wrap_model(model, DatasetWrapper(validation_features.float()), \"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b2d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d889777",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f54aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapped_model.predict(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc2e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrapped_model.predict_proba(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6870d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b47483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28aa81fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explainer = TabularExplainer(wrapped_model, validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d7fdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2184cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explainer = TabularExplainer(newmodel, validation_features.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.ext.blackbox import KernelExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18a1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = KernelExplainer(newmodel, np.array(validation_features.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a003a",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_explanation = explainer.explain_global(np.array(validation_features.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505c871b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted SHAP values\n",
    "print('ranked global importance values: {}'.format(global_explanation.get_ranked_global_values()))\n",
    "# Corresponding feature names\n",
    "print('ranked global importance names: {}'.format(global_explanation.get_ranked_global_names()))\n",
    "# Feature ranks (based on original order of features)\n",
    "print('global importance rank: {}'.format(global_explanation.global_importance_rank))\n",
    "\n",
    "# Note: Do not run this cell if using PFIExplainer, it does not support per class explanations\n",
    "# Per class feature names\n",
    "print('ranked per class feature names: {}'.format(global_explanation.get_ranked_per_class_names()))\n",
    "# Per class feature importance values\n",
    "print('ranked per class feature values: {}'.format(global_explanation.get_ranked_per_class_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb29e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a dictionary that holds the sorted feature importance names and values\n",
    "print('global importance rank: {}'.format(global_explanation.get_feature_importance_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce79a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature shap values for all features and all data points in the training data\n",
    "print('local importance values: {}'.format(global_explanation.local_importance_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d83a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf994e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ExplanationDashboard(global_explanation, newmodel, dataset=np.array(validation_features.float()), true_y=np.array(validation_labels.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b82bcc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f193bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_test = X_test[\"Survey, Relative, Peer's Average Review of Employee\"]\n",
    "\n",
    "from raiwidgets import FairnessDashboard\n",
    "\n",
    "# A_test contains your sensitive features (e.g., age, binary gender)\n",
    "# y_true contains ground truth labels\n",
    "# y_pred contains prediction labels\n",
    "\n",
    "FairnessDashboard(sensitive_features=A_test,\n",
    "                  y_true=np.array(validation_labels.float()).tolist(),\n",
    "                  y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272c76ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6742fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0579b114",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[str(col) for col in range(validation_features.float().shape[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb46c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1e318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4fa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Activity on Company Forums', 'Hired through SMTP','National Origin (code)', 'Negative Review in Past 5 Years', 'Survey, Relative, Attitude toward Peers', \"Survey, Relative, Peer's Average Attitude toward Environment\",\"Survey, Relative, Peer's Average Attitude toward Resources\", \"Survey, Relative, Peer's Average Attitude toward WorkType\", \"Survey, Relative, Peer's Average Attitude toward Workload\", \"Survey, Relative, Peer's Average Review of Employee\", \"University_Americanos College\", 'University_Kyrgyz National University', 'University_Rice University', 'University_Smolensk Humanitarian University', 'University_Universitas Negeri Jakarta', 'University_Universitas Pasundan', 'University_University of Commerce Luigi Bocconi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21685e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from raiwidgets import ErrorAnalysisDashboard\n",
    "\n",
    "ErrorAnalysisDashboard(global_explanation, newmodel, dataset=np.array(validation_features.float()), true_y=np.array(validation_labels.float()), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806c3120",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
